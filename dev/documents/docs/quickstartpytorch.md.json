{"attributes":{"backlinks":[{"tag":"document","title":"DataLoaders.jl","docid":"documents/README.md"},{"tag":"document","title":"toc","docid":"documents/toc.md"}],"path":"/home/runner/.julia/packages/DataLoaders/5uNNU/docs/quickstartpytorch.md","title":"Comparison to PyTorch"},"tag":"document","children":[{"attributes":{},"tag":"h1","children":[{"mimes":{"text/plain":"Comparison to PyTorch"}}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"This package is inspired by Pytorch"}},{"mimes":{"text/plain":"’"}},{"mimes":{"text/plain":"s "}},{"attributes":{"href":"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader","title":""},"tag":"a","children":[{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"torch.utils.data.DataLoader"}}]}]},{"mimes":{"text/plain":" and works a lot like it"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" The basic usage for both is "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"DataLoader(dataset, batchsize)"}}]},{"mimes":{"text/plain":", but for other use cases there are some differences"}},{"mimes":{"text/plain":"."}}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"The most important things are:"}}]},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"DataLoaders"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":"jl supports only map"}},{"mimes":{"text/plain":"-"}},{"mimes":{"text/plain":"style datasets at the moment"}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"It uses thread"}},{"mimes":{"text/plain":"-"}},{"mimes":{"text/plain":"based parallelism instead of process"}},{"mimes":{"text/plain":"-"}},{"mimes":{"text/plain":"based parallelism"}}]}]}]},{"attributes":{},"tag":"h2","children":[{"mimes":{"text/plain":"Detailed comparison"}}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"Let"}},{"mimes":{"text/plain":"’"}},{"mimes":{"text/plain":"s go through every argument to "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"torch.utils.data.DataLoader"}}]},{"mimes":{"text/plain":" and have a look at similarities and differences"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" See "}},{"attributes":{"reftype":"symbol","document_id":"references/DataLoaders.DataLoader"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"DataLoader"}}]}]},{"mimes":{"text/plain":" for a full list of its arguments"}},{"mimes":{"text/plain":"."}}]},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"dataset"}}]},{"mimes":{"text/plain":": This package currently only supports map"}},{"mimes":{"text/plain":"-"}},{"mimes":{"text/plain":"style datasets which work similarly to Python"}},{"mimes":{"text/plain":"’"}},{"mimes":{"text/plain":"s, but instead of implementing "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"__getindex__"}}]},{"mimes":{"text/plain":" and "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"__len__"}}]},{"mimes":{"text/plain":", you"}},{"mimes":{"text/plain":"’"}},{"mimes":{"text/plain":"d implement "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"LearnBase.getobs"}}]},{"mimes":{"text/plain":" and "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"nobs"}}]},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" "}},{"attributes":{"reftype":"document","href":"datacontainers.md","title":"","document_id":"documents/docs/datacontainers.md"},"tag":"reference","children":[{"mimes":{"text/plain":"More info here"}}]},{"mimes":{"text/plain":"."}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"batch_size = 1"}}]},{"mimes":{"text/plain":": If not specified otherwise, the default batch size is 1 for both packages"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" In DataLoaders"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":"jl, you can additionally pass in "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"nothing"}}]},{"mimes":{"text/plain":" to turn off batching"}},{"mimes":{"text/plain":"."}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"shuffle = false"}}]},{"mimes":{"text/plain":": This package"}},{"mimes":{"text/plain":"’"}},{"mimes":{"text/plain":"s "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"DataLoader"}}]},{"mimes":{"text/plain":" does "}},{"attributes":{},"tag":"strong","children":[{"mimes":{"text/plain":"not"}}]},{"mimes":{"text/plain":" support this argument"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" Shuffling should be applied to the dataset beforehand"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" See "}},{"attributes":{"reftype":"document","href":"howto/workingwith.md","title":"","document_id":"documents/docs/howto/workingwith.md"},"tag":"reference","children":[{"mimes":{"text/plain":"working with data containers"}}]},{"mimes":{"text/plain":"."}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"collate_fn"}}]},{"mimes":{"text/plain":": DataLoaders"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":"jl collates batches by default unless "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"collate = false"}}]},{"mimes":{"text/plain":" is passed"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" A custom collate function is not supported, but you can extend "}},{"attributes":{"reftype":"symbol","document_id":"references/DataLoaders.collate"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"DataLoaders.collate"}}]}]},{"mimes":{"text/plain":" for custom data types for the same effect"}},{"mimes":{"text/plain":"."}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"drop_last = False"}}]},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" DataLoaders"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":"jl has the same behavior of returning a partial batch by default, but the keyword argument is "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"partial = false"}}]},{"mimes":{"text/plain":" with "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"partial = not drop_last"}}]},{"mimes":{"text/plain":"."}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"prefetch_factor"}}]},{"mimes":{"text/plain":": This cannot be customized currently"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" The default behavior for DataLoaders"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":"jl is for every thread to be preloading one batch"}},{"mimes":{"text/plain":"."}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"pin_memory"}}]},{"mimes":{"text/plain":": DataLoaders"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":"jl does not interact with the GPU, but you can do this in your data container"}},{"mimes":{"text/plain":"."}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"num_workers"}}]},{"mimes":{"text/plain":", "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"persistent_workers"}}]},{"mimes":{"text/plain":", "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"worker_init_fn"}}]},{"mimes":{"text/plain":", "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"timeout"}}]},{"mimes":{"text/plain":": Unlike PyTorch, this package does not use multiprocessing, but multithreading which is not practical in Python due to the GIL"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" As such these arguments do not apply"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" Currently, DataLoaders"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":"jl will use either all threads except the primary one or all threads based on the keyword argument "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"useprimary = false"}}]},{"mimes":{"text/plain":"."}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"sampler"}}]},{"mimes":{"text/plain":", "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"batch_sampler"}}]},{"mimes":{"text/plain":", "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"generator"}}]},{"mimes":{"text/plain":": This package does not currently support these arguments for customizing the randomness"}},{"mimes":{"text/plain":"."}}]}]}]}]}